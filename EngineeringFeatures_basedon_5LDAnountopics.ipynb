{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we engineer several sets of features for prediction of Yelp rating from reviews.  The features here are derived from the results of LDA on the pooled reviews, which identified 5 topics.  First words in each review are tokenized and grouped by sentence. The 5 topic lda model is applied to each sentence. A sentence is assigned to a topic if that topic makes up more than 50% of that sentence. A sentiment analyzer is applied to the sentence.  The sentiment score of the topic for that review is the sum of the sentiment scores for the sentences assigned to that topic. The number of words assigned to the topic is also used.  Finally we measure the number of words used to describe each topic in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "#import en_core_web_sm\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops = pd.read_csv('./ProcessedData/coffeeshops_withcfcutoff.csv')\n",
    "reviews = pd.read_csv('./ProcessedData/allreviews_txtprocessed.csv')\n",
    "merged = pd.merge(shops,reviews,how='inner',on = ['alias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i can't believe i have never left a review for this place considering the amount of times i stop by here. and all the times i have been here not once has aone been rude to me. i always make sure to get a latter art so maybe the taro or red velvet or matcha to be honest i like them all  just the cuteness of it makes me love it. understandable that ma people don't wanna pay   -  for such small cups of latte but it is definitely based on preference  second -- the bingsoo here is so so good  the one i get the most has to be the mango cheesecake it literally has lives of cheesecakes and has condensed milk and all that good stuff - it's very sweet incase u don't like that  i really don't think it's a miss if you come here   they have individual and large bingsoos-- i get individual because i don't like sharing the goodness ....\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.mreviewtxt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the previously trained LDA model\n",
    "import pickle\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import LdaModel\n",
    "from gensim import corpora\n",
    "#Visualize the LDA topics\n",
    "dictionary = gensim.corpora.Dictionary.load('dictionary_allreviews_nouns.gensim')\n",
    "corpus = pickle.load(open('corpus_allreviews_nouns.pkl', 'rb'))\n",
    "\n",
    "temp_file = datapath(\"lda_nounsonly_5topics.gensim\")\n",
    "lda = gensim.models.ldamodel.LdaModel.load(temp_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0.05003922),\n",
       "  (1, 0.050024386),\n",
       "  (2, 0.3000926),\n",
       "  (3, 0.54981965),\n",
       "  (4, 0.050024122)],\n",
       " [(31, [3]), (419, [2]), (734, [3])],\n",
       " [(31, [(3, 0.9999051)]), (419, [(2, 0.9995777)]), (734, [(3, 0.998249)])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A simple example of applying the trained lda model to a new text\n",
    "other_texts = [\n",
    "['computer', 'time', 'table','-'],\n",
    "['survey', 'response', 'eps'],\n",
    "['human', 'system', 'coffee']]\n",
    "other_corpus = [dictionary.doc2bow(text) for text in other_texts]\n",
    "vector1 = lda[other_corpus[0]]\n",
    "vector1\n",
    "\n",
    "vector2 = lda[other_corpus[2]]\n",
    "vector2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.436, 'pos': 0.564, 'compound': 0.885}\n"
     ]
    }
   ],
   "source": [
    "#A simple example of applying vader to measure the sentiment in a sentence\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "vs = analyzer.polarity_scores('In some ways, they are totally opposite cataclysms. Good Awesome Terrific')\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divde up the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19590"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitrev = [str.split(merged.mreviewtxt[i],sep='.') for i in range(len(merged))]\n",
    "len(splitrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go through the \n",
    "\n",
    "sentenceldabyr = []\n",
    "sentimentspertopic = []\n",
    "senlenpertopic = []\n",
    "\n",
    "\n",
    "for review in splitrev:\n",
    "    ldavectors = []\n",
    "    reviewsbytopic = [0,0,0,0,0]\n",
    "    reviewlbytopic = [0,0,0,0,0]\n",
    "    for sentence in review:\n",
    "        vs = analyzer.polarity_scores(sentence)['compound']\n",
    "        splits = str.split(sentence)\n",
    "        slen = len(splits)\n",
    "        corpus = dictionary.doc2bow(splits)\n",
    "        ldav = lda[corpus][0]\n",
    "        ldavectors.append(ldav)\n",
    "        #Updating the sentiment score for each topic in the reviews\n",
    "        for (index,ldaf) in ldav:\n",
    "            reviewsbytopic[index] = reviewsbytopic[index] + vs*ldaf\n",
    "            reviewlbytopic[index] = reviewlbytopic[index] + slen*ldaf\n",
    "        \n",
    "    sentimentspertopic.append(reviewsbytopic)\n",
    "    senlenpertopic.append(reviewlbytopic)\n",
    "    sentenceldabyr.append(ldavectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentspertopicdf = pd.DataFrame(sentimentspertopic)\n",
    "sentimentspertopicdf.columns = ['t0s','t1s','t2s','t3s','t4s'] \n",
    "\n",
    "prefix = ['t0','t1','t2','t3','t4']\n",
    "senlenpertopicdf = pd.DataFrame(senlenpertopic)\n",
    "senlenpertopicdf.columns = [pref + 'senlen' for pref in prefix]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        t0s       t1s       t2s       t3s       t4s\n",
      "0 -0.010556  0.180251  0.012068  0.043956  0.890080\n",
      "1 -0.018792  0.144005  0.593450  0.760924  0.426514\n",
      "2  0.224952  0.406399  0.133696  0.774286  0.641366\n",
      "3  0.824146  0.814918  0.587349  0.898249  2.142437\n",
      "4 -0.037538  0.057878  0.631118  0.835730  0.167957\n",
      "    t0senlen   t1senlen   t2senlen   t3senlen   t4senlen\n",
      "0   1.687048  10.689785  47.067797  18.965432  85.014230\n",
      "1  13.649553   5.976947  23.739573  29.660751  13.973175\n",
      "2   4.881982   9.142167   4.172507  15.323400  38.479940\n",
      "3  34.537300  19.361009  26.728325  18.182833  48.190533\n",
      "4  33.489670  23.210480  58.604848  79.005441  18.135223\n",
      "(19590, 5)\n",
      "(19590, 5)\n"
     ]
    }
   ],
   "source": [
    "print(sentimentspertopicdf.head(5))\n",
    "print(senlenpertopicdf.head(5))\n",
    "print(sentimentspertopicdf.shape)\n",
    "print(senlenpertopicdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged1 = pd.concat([merged.reset_index(),sentimentspertopicdf,senlenpertopicdf],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19590, 32)\n",
      "   index                      id          name                  alias  \\\n",
      "0      0  UZViRVpxNZvOM5KarmbT1g  Sweet Moment  sweet-moment-new-york   \n",
      "1      1  UZViRVpxNZvOM5KarmbT1g  Sweet Moment  sweet-moment-new-york   \n",
      "2      2  UZViRVpxNZvOM5KarmbT1g  Sweet Moment  sweet-moment-new-york   \n",
      "3      3  UZViRVpxNZvOM5KarmbT1g  Sweet Moment  sweet-moment-new-york   \n",
      "4      4  UZViRVpxNZvOM5KarmbT1g  Sweet Moment  sweet-moment-new-york   \n",
      "\n",
      "   is_closed                                         categories  review_count  \\\n",
      "0      False  [{'alias': 'coffee', 'title': 'Coffee & Tea'},...           822   \n",
      "1      False  [{'alias': 'coffee', 'title': 'Coffee & Tea'},...           822   \n",
      "2      False  [{'alias': 'coffee', 'title': 'Coffee & Tea'},...           822   \n",
      "3      False  [{'alias': 'coffee', 'title': 'Coffee & Tea'},...           822   \n",
      "4      False  [{'alias': 'coffee', 'title': 'Coffee & Tea'},...           822   \n",
      "\n",
      "  price  rating_x transactions  ...       t0s       t1s       t2s       t3s  \\\n",
      "0    $$       4.5           []  ... -0.010556  0.180251  0.012068  0.043956   \n",
      "1    $$       4.5           []  ... -0.018792  0.144005  0.593450  0.760924   \n",
      "2    $$       4.5           []  ...  0.224952  0.406399  0.133696  0.774286   \n",
      "3    $$       4.5           []  ...  0.824146  0.814918  0.587349  0.898249   \n",
      "4    $$       4.5           []  ... -0.037538  0.057878  0.631118  0.835730   \n",
      "\n",
      "        t4s   t0senlen   t1senlen   t2senlen   t3senlen   t4senlen  \n",
      "0  0.890080   1.687048  10.689785  47.067797  18.965432  85.014230  \n",
      "1  0.426514  13.649553   5.976947  23.739573  29.660751  13.973175  \n",
      "2  0.641366   4.881982   9.142167   4.172507  15.323400  38.479940  \n",
      "3  2.142437  34.537300  19.361009  26.728325  18.182833  48.190533  \n",
      "4  0.167957  33.489670  23.210480  58.604848  79.005441  18.135223  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "Index(['index', 'id', 'name', 'alias', 'is_closed', 'categories',\n",
      "       'review_count', 'price', 'rating_x', 'transactions', 'latitude',\n",
      "       'longitude', 'geometry', 'catlist', 'numcoffeemen', 'numreviews',\n",
      "       'fraccof', 'idx', 'date', 'rating_y', 'reviewtxt', 'mreviewtxt', 't0s',\n",
      "       't1s', 't2s', 't3s', 't4s', 't0senlen', 't1senlen', 't2senlen',\n",
      "       't3senlen', 't4senlen'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged1.shape)\n",
    "print(merged1.head(5))\n",
    "print(merged1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged1.to_csv('./ProcessedData/reviews_withlda5topicfeatures.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_envp3",
   "language": "python",
   "name": "nlp_envp3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
